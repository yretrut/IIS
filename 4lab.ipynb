{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcDykXpaNtNz5OJsJmw2Af",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yretrut/IIS/blob/main/4lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Лабораторная работа 4**\n",
        "\n",
        "**Построение нейросети. Часть 1**"
      ],
      "metadata": {
        "id": "vHyb37oY-fm1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Написание Python кода\n",
        "Хоть мы и не будем использовать библиотеки с нейронными сетями, мы импортируем 4 метода из математической библиотеки numpy. А именно:\n",
        "\n",
        "exp — экспоненцирование\n",
        "\n",
        "array — создание матрицы\n",
        "\n",
        "dot — перемножения матриц\n",
        "\n",
        "random — генерация случайных чисел\n"
      ],
      "metadata": {
        "id": "khVqLPcxBX8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-Y0h84T-baz"
      },
      "outputs": [],
      "source": [
        "from numpy import exp, array, random, dot\n",
        "training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "training_set_outputs = array([[0, 1, 1, 0]]).T"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "«.T» — функция транспонирования матриц. "
      ],
      "metadata": {
        "id": "20BLoWMDBssf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем необходимые библиотеки\n",
        "from numpy import exp, array, random, dot\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self):\n",
        "        # Заполните генератор случайных чисел, чтобы он генерировал одни и те \n",
        "        # же числа при каждом запуске программы\n",
        "        random.seed(1)\n",
        "\n",
        "        # Мы моделируем один нейрон с 3 входными подключениями и 1 выходным \n",
        "        # Мы назначаем случайные веса матрице 3 x 1 со значениями в диапазоне \n",
        "        # от -1 до 1 и средним значением 0.\n",
        "   \n",
        "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
        "\n",
        "    # Сигмовидная функция, описывающая S-образную кривую.    \n",
        "    # Мы передаем взвешенную сумму входных данных через эту функцию, чтобы \n",
        "    # нормализовать их от 0 до 1.\n",
        "    def __sigmoid(self, x):\n",
        "        return 1 / (1 + exp(-x))\n",
        "\n",
        "    # Производная сигмовидной функции.\n",
        "    # Это градиент сигмовидной кривой.\n",
        "    # Это показывает, насколько мы уверены в существующем весе.\n",
        "    def __sigmoid_derivative(self, x):\n",
        "        return x * (1 - x)\n",
        "\n",
        "    # Мы обучаем нейронную сеть методом проб и ошибок.\n",
        "    # Каждый раз регулируя синаптические веса.\n",
        "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
        "        for iteration in range(number_of_training_iterations):\n",
        "            # Передайем обучающий набор через нашу нейронную сеть (отдельный нейрон).\n",
        "            output = self.think(training_set_inputs)\n",
        "\n",
        "            # Вычислите ошибку (разницу между желаемым и прогнозируемым выходными данными).\n",
        "            error = training_set_outputs - output\n",
        "\n",
        "            # Умножьте ошибку на вход и снова на градиент сигмовидной кривой.\n",
        "            # Это означает, что менее уверенные веса корректируются больше.\n",
        "            # Это означает, что входные данные, которые равны нулю, не вызывают изменения весов.\n",
        "            adjustment = dot(training_set_inputs.T, error * self.__sigmoid_derivative(output))\n",
        "\n",
        "            # Отрегулируйте веса.\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "    \n",
        "    def think(self, inputs):\n",
        "        # Передайте входные данные через нашу нейронную сеть (наш единственный нейрон).\n",
        "        return self.__sigmoid(dot(inputs, self.synaptic_weights))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Инициализируйте нейронную сеть с одним нейроном.\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print (\"Случайные начальные синаптические веса:\")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Обучающий набор. У нас есть 4 примера, каждый из которых состоит из 3 \n",
        "    # входных значений и 1 выходного значения.\n",
        "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "    training_set_outputs = array([[0, 1, 1, 0]]).T\n",
        "\n",
        "    # Обучите нейронную сеть с помощью обучающего набора.\n",
        "    # Количество итераций - 10 000 раз \n",
        "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
        "\n",
        "    print (\"Новые синаптические веса после тренировки: \")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Протестируйте нейронную сеть в новой ситуации.\n",
        "    print (\"Учитывая новую ситуацию [1, 0, 0] -> ?: \")\n",
        "    print (neural_network.think(array([1, 0, 0])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z2nEqkfBvND",
        "outputId": "073e6beb-3273-41d9-a7b3-0b625f891c9f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Случайные начальные синаптические веса:\n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Новые синаптические веса после тренировки: \n",
            "[[ 9.67299303]\n",
            " [-0.2078435 ]\n",
            " [-4.62963669]]\n",
            "Учитывая новую ситуацию [1, 0, 0] -> ?: \n",
            "[0.99993704]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В искусственных нейронных сетях функция активации нейрона определяет выходной сигнал, который определяется входным сигналом или набором входных сигналов. Стандартная компьютерная микросхема может рассматриваться как цифровая сеть функций активации, которые могут принимать значения «ON» (1) или «OFF» (0) в зависимости от входа. Это похоже на поведение линейного перцептрона в нейронных сетях. Однако только нелинейные функции активации позволяют таким сетям решать нетривиальные задачи с использованием малого числа узлов. В искусственных нейронных сетях эта функция также называется передаточной функцией.\n",
        "\n",
        "Используем Функцию активации SoftPlus:"
      ],
      "metadata": {
        "id": "cZF7fNdgE_6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем необходимые библиотеки\n",
        "from numpy import exp, array, random, dot, log\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self):\n",
        "        # Заполните генератор случайных чисел, чтобы он генерировал одни и те \n",
        "        # же числа при каждом запуске программы\n",
        "        random.seed(1)\n",
        "\n",
        "        # Мы моделируем один нейрон с 3 входными подключениями и 1 выходным \n",
        "        # Мы назначаем случайные веса матрице 3 x 1 со значениями в диапазоне \n",
        "        # от -1 до 1 и средним значением 0.\n",
        "   \n",
        "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
        "\n",
        "    # Сигмовидная функция, описывающая S-образную кривую.    \n",
        "    # Мы передаем взвешенную сумму входных данных через эту функцию, чтобы \n",
        "    # нормализовать их от 0 до 1.\n",
        "    def SoftPlus(self, x):\n",
        "        return log(1+exp(x))\n",
        "\n",
        "    # Производная сигмовидной функции.\n",
        "    # Это градиент сигмовидной кривой.\n",
        "    # Это показывает, насколько мы уверены в существующем весе.\n",
        "    def SoftPlus_derivative(self, x):\n",
        "        return 1/(1+exp(-x))\n",
        "\n",
        "    # Мы обучаем нейронную сеть методом проб и ошибок.\n",
        "    # Каждый раз регулируя синаптические веса.\n",
        "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
        "        for iteration in range(number_of_training_iterations):\n",
        "            # Передайем обучающий набор через нашу нейронную сеть (отдельный нейрон).\n",
        "            output = self.think(training_set_inputs)\n",
        "\n",
        "            # Вычислите ошибку (разницу между желаемым и прогнозируемым выходными данными).\n",
        "            error = training_set_outputs - output\n",
        "\n",
        "            # Умножьте ошибку на вход и снова на градиент сигмовидной кривой.\n",
        "            # Это означает, что менее уверенные веса корректируются больше.\n",
        "            # Это означает, что входные данные, которые равны нулю, не вызывают изменения весов.\n",
        "            adjustment = dot(training_set_inputs.T, error * self.SoftPlus_derivative(output))\n",
        "\n",
        "            # Отрегулируйте веса.\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "    \n",
        "    def think(self, inputs):\n",
        "        # Передайте входные данные через нашу нейронную сеть (наш единственный нейрон).\n",
        "        return self.SoftPlus(dot(inputs, self.synaptic_weights))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Инициализируйте нейронную сеть с одним нейроном.\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print (\"Случайные начальные синаптические веса:\")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Обучающий набор. У нас есть 4 примера, каждый из которых состоит из 3 \n",
        "    # входных значений и 1 выходного значения.\n",
        "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "    training_set_outputs = array([[0, 1, 1, 0]]).T\n",
        "\n",
        "    # Обучите нейронную сеть с помощью обучающего набора.\n",
        "    # Количество итераций - 10 000 раз \n",
        "    neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
        "\n",
        "    print (\"Новые синаптические веса после тренировки: \")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Протестируйте нейронную сеть в новой ситуации.\n",
        "    print (\"Учитывая новую ситуацию [1, 0, 0] -> ?: \")\n",
        "    print (neural_network.think(array([1, 0, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT3w-ahgQzwm",
        "outputId": "3403d817-79ed-4d5f-f08b-eb08a92127f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Случайные начальные синаптические веса:\n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Новые синаптические веса после тренировки: \n",
            "[[ 8.81163116]\n",
            " [-0.15081447]\n",
            " [-8.73786946]]\n",
            "Учитывая новую ситуацию [1, 0, 0] -> ?: \n",
            "[8.81178014]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В строке \n",
        "neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
        "заменим количество итераций на 1000, на 100.\n"
      ],
      "metadata": {
        "id": "xfxlvh7bT858"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Подключаем необходимые библиотеки\n",
        "from numpy import exp, array, random, dot, log\n",
        "\n",
        "class NeuralNetwork():\n",
        "    def __init__(self):\n",
        "        # Заполните генератор случайных чисел, чтобы он генерировал одни и те \n",
        "        # же числа при каждом запуске программы\n",
        "        random.seed(1)\n",
        "\n",
        "        # Мы моделируем один нейрон с 3 входными подключениями и 1 выходным \n",
        "        # Мы назначаем случайные веса матрице 3 x 1 со значениями в диапазоне \n",
        "        # от -1 до 1 и средним значением 0.\n",
        "   \n",
        "        self.synaptic_weights = 2 * random.random((3, 1)) - 1\n",
        "\n",
        "    # Сигмовидная функция, описывающая S-образную кривую.    \n",
        "    # Мы передаем взвешенную сумму входных данных через эту функцию, чтобы \n",
        "    # нормализовать их от 0 до 1.\n",
        "    def SoftPlus(self, x):\n",
        "        return log(1+exp(x))\n",
        "\n",
        "    # Производная сигмовидной функции.\n",
        "    # Это градиент сигмовидной кривой.\n",
        "    # Это показывает, насколько мы уверены в существующем весе.\n",
        "    def SoftPlus_derivative(self, x):\n",
        "        return 1/(1+exp(-x))\n",
        "\n",
        "    # Мы обучаем нейронную сеть методом проб и ошибок.\n",
        "    # Каждый раз регулируя синаптические веса.\n",
        "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
        "        for iteration in range(number_of_training_iterations):\n",
        "            # Передайем обучающий набор через нашу нейронную сеть (отдельный нейрон).\n",
        "            output = self.think(training_set_inputs)\n",
        "\n",
        "            # Вычислите ошибку (разницу между желаемым и прогнозируемым выходными данными).\n",
        "            error = training_set_outputs - output\n",
        "\n",
        "            # Умножьте ошибку на вход и снова на градиент сигмовидной кривой.\n",
        "            # Это означает, что менее уверенные веса корректируются больше.\n",
        "            # Это означает, что входные данные, которые равны нулю, не вызывают изменения весов.\n",
        "            adjustment = dot(training_set_inputs.T, error * self.SoftPlus_derivative(output))\n",
        "\n",
        "            # Отрегулируйте веса.\n",
        "            self.synaptic_weights += adjustment\n",
        "\n",
        "    \n",
        "    def think(self, inputs):\n",
        "        # Передайте входные данные через нашу нейронную сеть (наш единственный нейрон).\n",
        "        return self.SoftPlus(dot(inputs, self.synaptic_weights))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # Инициализируйте нейронную сеть с одним нейроном.\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    print (\"Случайные начальные синаптические веса:\")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Обучающий набор. У нас есть 4 примера, каждый из которых состоит из 3 \n",
        "    # входных значений и 1 выходного значения.\n",
        "    training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
        "    training_set_outputs = array([[0, 1, 1, 0]]).T\n",
        "\n",
        "    # Обучите нейронную сеть с помощью обучающего набора.\n",
        "    # Количество итераций - 100 раз \n",
        "    neural_network.train(training_set_inputs, training_set_outputs, 100)\n",
        "\n",
        "    print (\"Новые синаптические веса после тренировки: \")\n",
        "    print (neural_network.synaptic_weights)\n",
        "\n",
        "    # Протестируйте нейронную сеть в новой ситуации.\n",
        "    print (\"Учитывая новую ситуацию [1, 0, 0] -> ?: \")\n",
        "    print (neural_network.think(array([1, 0, 0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgeKgzPzUCm-",
        "outputId": "0802c875-2f44-4fba-e6c7-3f80b66d7385"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Случайные начальные синаптические веса:\n",
            "[[-0.16595599]\n",
            " [ 0.44064899]\n",
            " [-0.99977125]]\n",
            "Новые синаптические веса после тренировки: \n",
            "[[ 4.22173258]\n",
            " [-0.16805727]\n",
            " [-4.13290161]]\n",
            "Учитывая новую ситуацию [1, 0, 0] -> ?: \n",
            "[4.23629918]\n"
          ]
        }
      ]
    }
  ]
}